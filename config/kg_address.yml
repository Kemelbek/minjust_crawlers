# Scraper for the OCCRP web site.
# The goal is not to download all HTML, but only PDFs & other documents
# linked from the page as proof.
name: kg_address

# A title for display in the UI:
description: 'State registry of addresses in Bishkek'

# Uncomment to run this scraper automatically:
schedule: daily
delay: 1
stealthy: true
pipeline:

  init:
    # This first stage will get the ball rolling with a seed URL.
    method: seed
    params:
      urls:
        - http://address.darek.gosreg.kg/search/street/7402
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=2#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=3#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=4#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=5#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=6#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=7#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=8#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=9#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=10#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=11#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=12#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=13#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=14#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=15#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=16#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=17#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=18#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=19#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=20#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=21#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=22#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=23#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=24#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=25#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=26#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=27#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=28#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=29#
        # - http://address.darek.gosreg.kg/search/street/7402?streetType=0&streetName=&filter=sort&page=30#

    handle:
      pass: fetch

  fetch:
    # Download the seed page
    method: fetch
    params:
      # These rules specify which pages should be scraped or included:
      rules:
        and:
          - domain: http://address.darek.gosreg.kg
    handle:
      pass: parse

  parse:
    # Parse the scraped pages to find if they contain additional links.
    method: example.kg_address_parse:parse
    handle:
      # this makes it a recursive web crawler:
      store: extractdata
      fetch: fetch
  
  extractdata:
    # Parse the scraped pages to extract useful information
    method: example.kg_address:extractdata
    handle:
      pass: store

  store:
    # Store the crawled documents to a directory
    method: db
    params:
      table: "kg_address"
      unique:
        